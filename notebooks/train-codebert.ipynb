{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "tpu",  // Updated to enable TPU v3-8
   "dataSources": [],
   "dockerImageVersionId": 31013,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# CodeBERT for Swift Code Understanding\n\nIn this notebook, we fine-tune the [CodeBERT](https://github.com/microsoft/CodeBERT) model on the [Swift Code Intelligence dataset](https://huggingface.co/datasets/mvasiliniuc/iva-swift-codeint). CodeBERT is a pre-trained model designed for programming languages, ideal for code-related tasks.\n\nWe'll use the Swift code dataset for a binary classification task (detecting `Package.swift` files). After training, we'll upload the model to Dropbox.\n\n## Overview\n\n1. **ðŸ”§ Setup**: Install libraries and configure TPU\n2. **ðŸ“¥ Data Loading**: Load the dataset\n3. **ðŸ§¹ Preprocessing**: Tokenize and label data\n4. **ðŸ§  Model Training**: Fine-tune CodeBERT\n5. **ðŸ“Š Evaluation**: Assess performance\n6. **ðŸ“¤ Export & Upload**: Save and upload to Dropbox",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install transformers datasets evaluate torch scikit-learn tqdm dropbox requests torch_xla accelerate -U\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import os\nimport json\nimport torch\nimport random\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n    DataCollatorWithPadding\n)\nfrom accelerate import Accelerator\nimport torch_xla.core.xla_model as xm\n\n# Set a seed for reproducibility\nset_seed(42)\n\n# Initialize Accelerator for TPU support\ntry:\n    accelerator = Accelerator()\n    device = accelerator.device\n    print(f\"Using device: {device}\")\nexcept Exception as e:\n    print(f\"Error initializing accelerator: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset and Model Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Set model and dataset IDs\nMODEL_ID = \"microsoft/codebert-base\"\nDATASET_ID = \"mvasiliniuc/iva-swift-codeint\"\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Data Loading",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load the dataset\ntry:\n    data = load_dataset(DATASET_ID, trust_remote_code=True)\n    print(\"Dataset structure:\")\n    print(data)\nexcept Exception as e:\n    print(f\"Error loading dataset: {e}\")\n    raise\n\n# Analyze sequence lengths to set max_length\ndata_sample = data['train'][:1000] if 'train' in data else data[list(data.keys())[0]][:1000]\nlengths = [len(tokenizer.encode(sample['content'])) for sample in data_sample]\nmax_length = min(512, int(np.percentile(lengths, 95)))\nprint(f\"Determined max_length: {max_length}\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Example from the dataset\ntry:\n    example = data['train'][0] if 'train' in data else data[list(data.keys())[0]][0]\n    print(\"Example features:\")\n    for key, value in example.items():\n        if isinstance(value, str) and len(value) > 100:\n            print(f\"{key}: {value[:100]}...\")\n        else:\n            print(f\"{key}: {value}\")\nexcept Exception as e:\n    print(f\"Error accessing example: {e}\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Loading the CodeBERT Tokenizer",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load the CodeBERT tokenizer\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n    print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n    print(f\"Tokenizer type: {tokenizer.__class__.__name__}\")\nexcept Exception as e:\n    print(f\"Error loading tokenizer: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Data Preparation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Add labels for Package.swift detection\ndef add_labels(example):\n    example['label'] = 1 if 'Package.swift' in example['path'] else 0\n    return example\n\ntry:\n    labeled_data = data['train'].map(add_labels)\n    \n    # Check label distribution\n    import collections\n    all_labels = labeled_data['label']\n    label_counter = collections.Counter(all_labels)\n    print(\"Label distribution:\")\n    for label, count in label_counter.items():\n        print(f\"Label {label}: {count} examples ({count/len(labeled_data)*100:.2f}%)\")\n    \n    # Handle imbalance with class weights\n    from sklearn.utils.class_weight import compute_class_weight\n    class_weights = compute_class_weight('balanced', classes=[0, 1], y=all_labels)\n    print(f\"Computed class weights: {dict(enumerate(class_weights))}\")\nexcept Exception as e:\n    print(f\"Error preparing data: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Split the dataset with stratification\ntry:\n    train_test_split = labeled_data.train_test_split(test_size=0.1, stratify=labeled_data['label'], seed=42)\n    train_data = train_test_split['train']\n    val_data = train_test_split['test']\n    \n    # Verify label distribution\n    train_label_counter = collections.Counter(train_data['label'])\n    val_label_counter = collections.Counter(val_data['label'])\n    print(f\"Training set size: {len(train_data)}\")\n    print(f\"Training label distribution: {dict(train_label_counter)}\")\n    print(f\"Validation set size: {len(val_data)}\")\n    print(f\"Validation label distribution: {dict(val_label_counter)}\")\nexcept Exception as e:\n    print(f\"Error splitting data: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Tokenization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def tokenize_function(examples):\n    return tokenizer(\n        examples[\"content\"],\n        padding=\"max_length\" if max_length == 512 else \"longest\",  # Dynamic padding\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\"\n    )\n\ntry:\n    tokenized_train_data = train_data.map(\n        tokenize_function,\n        batched=True,\n        remove_columns=[col for col in train_data.column_names if col != 'label']\n    )\n    tokenized_val_data = val_data.map(\n        tokenize_function,\n        batched=True,\n        remove_columns=[col for col in val_data.column_names if col != 'label']\n    )\n    print(\"Training data after tokenization:\")\n    print(tokenized_train_data)\n    print(\"\\nValidation data after tokenization:\")\n    print(tokenized_val_data)\nexcept Exception as e:\n    print(f\"Error tokenizing data: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Model Preparation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load the CodeBERT model\ntry:\n    model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, num_labels=2)\n    model = accelerator.prepare(model)  # Move to TPU with accelerator\n    print(f\"Model type: {model.__class__.__name__}\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Training Setup",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    accuracy = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average='weighted')\n    return {'accuracy': accuracy, 'f1': f1}\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "training_args = TrainingArguments(\n    output_dir=\"./results/codebert-swift\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=16,  // Increased for TPU efficiency\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=500,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    push_to_hub=False,\n    class_weights=list(class_weights)  // Apply class weights\n)\n\n# Create Trainer with data collator for dynamic padding\ntry:\n    data_collator = DataCollatorWithPadding(tokenizer)\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train_data,\n        eval_dataset=tokenized_val_data,\n        compute_metrics=compute_metrics,\n        tokenizer=tokenizer,\n        data_collator=data_collator\n    )\n    trainer = accelerator.prepare(trainer)  // Prepare Trainer for TPU\nexcept Exception as e:\n    print(f\"Error setting up trainer: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Training the Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "try:\n    print(\"Starting model training...\")\n    trainer.train()\nexcept Exception as e:\n    print(f\"Error during training: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Evaluating the Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "try:\n    eval_results = trainer.evaluate()\n    print(f\"Evaluation results: {eval_results}\")\nexcept Exception as e:\n    print(f\"Error during evaluation: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Testing the Model with Example Predictions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "try:\n    test_examples = val_data.select(range(5))\n    tokenized_test_examples = tokenize_function({\"content\": test_examples[\"content\"]})\n    for key, val in tokenized_test_examples.items():\n        if isinstance(val, torch.Tensor):\n            tokenized_test_examples[key] = val.to(device)\n    \n    with torch.no_grad():\n        outputs = model(**{k: v for k, v in tokenized_test_examples.items() if k != \"label\"})\n        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n        predicted_labels = torch.argmax(predictions, dim=-1).cpu().numpy()\n    \n    for i, (pred, true) in enumerate(zip(predicted_labels, test_examples[\"label\"])):\n        is_package_swift = \"Yes\" if pred == 1 else \"No\"\n        true_is_package_swift = \"Yes\" if true == 1 else \"No\"\n        print(f\"File path: {test_examples['path'][i]}\")\n        print(f\"Prediction: Is Package.swift? {is_package_swift} (Confidence: {predictions[i][pred].item():.4f})\")\n        print(f\"True label: Is Package.swift? {true_is_package_swift}\")\n        print(f\"First few lines: {test_examples['content'][i][:100]}...\")\n        print(\"---\\n\")\nexcept Exception as e:\n    print(f\"Error during prediction: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Saving the Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "try:\n    model_save_dir = \"./codebert-swift-model\"\n    os.makedirs(model_save_dir, exist_ok=True)\n    model.save_pretrained(model_save_dir)\n    tokenizer.save_pretrained(model_save_dir)\n    print(f\"Model and tokenizer saved to {model_save_dir}\")\nexcept Exception as e:\n    print(f\"Error saving model: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Uploading to Dropbox",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import zipfile\nimport dropbox\nfrom dropbox.files import WriteMode\nfrom dropbox.exceptions import ApiError\n\ndef zip_directory(directory, output_path):\n    try:\n        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for root, _, files in os.walk(directory):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, os.path.relpath(file_path, os.path.dirname(directory)))\n        print(f\"Created zip file: {output_path}\")\n    except Exception as e:\n        print(f\"Error zipping directory: {e}\")\n        raise\n\ntry:\n    model_zip_path = \"./codebert-swift-model.zip\"\n    zip_directory(model_save_dir, model_zip_path)\n    zip_size_mb = os.path.getsize(model_zip_path) / (1024 * 1024)\n    print(f\"Zip file size: {zip_size_mb:.2f} MB\")\nexcept Exception as e:\n    print(f\"Error preparing zip: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "APP_KEY = \"2bi422xpd3xd962\"\nAPP_SECRET = \"j3yx0b41qdvfu86\"\nREFRESH_TOKEN = \"RvyL03RE5qAAAAAAAAAAAVMVebvE7jDx8Okd0ploMzr85c6txvCRXpJAt30mxrKF\"\n\ndef get_dropbox_client():\n    try:\n        dbx = dropbox.Dropbox(app_key=APP_KEY, app_secret=APP_SECRET, oauth2_refresh_token=REFRESH_TOKEN)\n        dbx.users_get_current_account()\n        return dbx\n    except AuthError as e:\n        print(f\"ERROR: Invalid credentials. {e}\")\n        return None\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def upload_file_to_dropbox(file_path, dropbox_path):\n    dbx = get_dropbox_client()\n    if not dbx:\n        return False\n    \n    try:\n        with open(file_path, 'rb') as f:\n            file_size = os.path.getsize(file_path)\n            chunk_size = 4 * 1024 * 1024\n            if file_size <= chunk_size:\n                print(f\"Uploading {file_path} to Dropbox as {dropbox_path}...\")\n                dbx.files_upload(f.read(), dropbox_path, mode=WriteMode('overwrite'))\n                print(\"Upload complete!\")\n            else:\n                print(f\"Uploading {file_path} to Dropbox as {dropbox_path} in chunks...\")\n                upload_session_start_result = dbx.files_upload_session_start(f.read(chunk_size))\n                cursor = dropbox.files.UploadSessionCursor(session_id=upload_session_start_result.session_id, offset=f.tell())\n                commit = dropbox.files.CommitInfo(path=dropbox_path, mode=WriteMode('overwrite'))\n                uploaded = f.tell()\n                with tqdm(total=file_size, desc=\"Uploading\", unit=\"B\", unit_scale=True) as pbar:\n                    pbar.update(uploaded)\n                    while uploaded < file_size:\n                        if (file_size - uploaded) <= chunk_size:\n                            data = f.read(chunk_size)\n                            dbx.files_upload_session_finish(data, cursor, commit)\n                            uploaded += len(data)\n                            pbar.update(len(data))\n                        else:\n                            data = f.read(chunk_size)\n                            dbx.files_upload_session_append_v2(data, cursor)\n                            uploaded += len(data)\n                            cursor.offset = uploaded\n                            pbar.update(len(data))\n                print(\"Chunked upload complete!\")\n        return True\n    except ApiError as e:\n        print(f\"ERROR: Dropbox API error - {e}\")\n        return False\n    except Exception as e:\n        print(f\"Error uploading to Dropbox: {e}\")\n        return False\n\ntry:\n    dropbox_path = \"/codebert-swift-model/codebert-swift-model.zip\"\n    for attempt in range(3):  // Retry logic\n        if upload_file_to_dropbox(model_zip_path, dropbox_path):\n            break\n        print(f\"Retry attempt {attempt + 1}/3...\")\n        time.sleep(10)\n    else:\n        print(\"Failed to upload model to Dropbox after 3 attempts.\")\n    if os.path.exists(dropbox_path):\n        print(f\"Successfully uploaded model to Dropbox at {dropbox_path}\")\nexcept Exception as e:\n    print(f\"Error in upload process: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Creating a Shareable Link",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def create_shared_link(dropbox_path):\n    dbx = get_dropbox_client()\n    if not dbx:\n        return None\n    try:\n        shared_link = dbx.sharing_create_shared_link_with_settings(dropbox_path)\n        return shared_link.url\n    except ApiError as e:\n        if isinstance(e.error, dropbox.sharing.CreateSharedLinkWithSettingsError) and e.error.is_shared_link_already_exists():\n            links = dbx.sharing_list_shared_links(dropbox_path).links\n            return links[0].url if links else None\n        print(f\"ERROR: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Error creating shared link: {e}\")\n        return None\n\ntry:\n    shared_link = create_shared_link(dropbox_path)\n    if shared_link:\n        download_link = shared_link.replace(\"www.dropbox.com\", \"dl.dropboxusercontent.com\").replace(\"?dl=0\", \"\")\n        print(f\"Download link: {download_link}\")\n    else:\n        print(\"Failed to create shared link.\")\nexcept Exception as e:\n    print(f\"Error in link creation: {e}\")\n    raise\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion\n\n1. Loaded and prepared the Swift code dataset\n2. Fine-tuned CodeBERT for `Package.swift` classification\n3. Evaluated and tested the model\n4. Saved and uploaded to Dropbox\n\nThis model can be used for Swift code understanding tasks.",
   "metadata": {}
  }
 ]
}